{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredients:\n",
      "- 1 bottle of Soju\n",
      "- Ice cubes\n",
      "- Water\n",
      "\n",
      "Instructions:\n",
      "1. Chill the bottle of Soju in the refrigerator for at least 2 hours before serving.\n",
      "2. Fill a shot glass with Soju.\n",
      "3. Serve the Soju with ice cubes on the side.\n",
      "4. If desired, dilute the Soju with water to taste.\n",
      "5. Enjoy your Soju! Ingredients:\n",
      "- 1 medium Napa cabbage\n",
      "- 1/4 cup sea salt\n",
      "- 4 cups water\n",
      "- 1 tablespoon grated ginger\n",
      "- 4 cloves garlic, minced\n",
      "- 1 tablespoon sugar\n",
      "- 3 tablespoons Korean red pepper flakes (gochugaru)\n",
      "- 2 tablespoons fish sauce\n",
      "- 2 tablespoons soy sauce\n",
      "- 1 small daikon radish, julienned\n",
      "- 4 green onions, chopped\n",
      "\n",
      "Instructions:\n",
      "1. Cut the Napa cabbage into quarters lengthwise and remove the core. Cut each quarter into 2-inch pieces.\n",
      "2. In a large bowl, dissolve the sea salt in water. Add the cabbage pieces and let them soak for 2 hours, turning occasionally.\n",
      "3. Rinse the cabbage under cold water and drain well.\n",
      "4. In a separate bowl, mix together the ginger, garlic, sugar, red pepper flakes, fish sauce, and soy sauce.\n",
      "5. Add the daikon radish and green onions to the spice mixture and mix well.\n",
      "6. Gently squeeze any excess water from the cabbage and add it to the spice mixture. Mix well to coat the cabbage evenly.\n",
      "7. Pack the kimchi into a clean glass jar, pressing down firmly to remove any air bubbles.\n",
      "8. Cover the jar loosely with a lid and let it ferment at room temperature for 1-5 days, depending on your preference for sourness.\n",
      "9. Once fermented, store the kimchi in the refrigerator. It will continue to ferment and develop flavor over time. Enjoy! \n",
      "\n",
      "Tokens Used: 431\n",
      "\tPrompt Tokens: 28\n",
      "\tCompletion Tokens: 403\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.000848\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.llms.openai import OpenAI\n",
    "\n",
    "# Calculating the token usage and price\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "with get_openai_callback() as usage:\n",
    "    a = chat.predict(\"What is the recipe for Soju\")\n",
    "    b = chat.predict(\"What is the recipe for Kimchi\")\n",
    "    print(a,b,\"\\n\")\n",
    "    print(usage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/USER/Documents/fullStack-GPT/env/lib/python3.11/site-packages/langchain/llms/openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/USER/Documents/fullStack-GPT/env/lib/python3.11/site-packages/langchain/llms/openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenAIChat(client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo-16k', model_kwargs={'temperature': 0.1, 'max_tokens': 400, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.llms.loading import load_llm\n",
    "chat = OpenAI(\n",
    "    temperature=0.1,\n",
    "    max_tokens=400,\n",
    "    model=\"gpt-3.5-turbo-16k\"\n",
    ")\n",
    "\n",
    "chat = load_llm(\"model.json\")\n",
    "\n",
    "chat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
